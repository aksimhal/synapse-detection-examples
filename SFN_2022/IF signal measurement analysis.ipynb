{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naked-history",
   "metadata": {},
   "source": [
    "# Signal Matching Analysis for SfN Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import webknossos as wk\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from at_synapse_detection import SynapseDetection as syn\n",
    "from PIL import Image, ImageSequence\n",
    "from skimage import measure\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "from skimage import io\n",
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-cruise",
   "metadata": {},
   "source": [
    "## Synapse detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-chamber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psd_vol = skio.imread('data/F002-PSD95-4th.tif', plugin='tifffile')\n",
    "psd_data = np.transpose(psd_vol, (1, 2, 0))\n",
    "\n",
    "syn_vol = skio.imread('data/F002-Syn12-2nd.tif', plugin='tifffile')\n",
    "synapsin_data = np.transpose(syn_vol, (1, 2, 0))\n",
    "\n",
    "synapsin_data = np.double(synapsin_data)\n",
    "psd_data = np.double(psd_data)\n",
    "\n",
    "# select only slices 5-48\n",
    "synapsin_data = synapsin_data[:, :, 4:]\n",
    "psd_data = psd_data[:, :, 4:]\n",
    "\n",
    "\n",
    "# Create a dictionary object to hold the image data \n",
    "synaptic_volumes = {'presynaptic': [synapsin_data], 'postsynaptic': [psd_data]}\n",
    "\n",
    "# Specify the minimum number of slices each blob should span \n",
    "min_num_of_slices = 1\n",
    "\n",
    "# Create query dictionary object \n",
    "query = {'preIF': ['synapsin_data',], 'preIF_z': [1],\n",
    "         'postIF': ['psd_data'], 'postIF_z': [2],\n",
    "         'punctumSize': 2}\n",
    "\n",
    "result_vol = syn.getSynapseDetections(synaptic_volumes, query)\n",
    "label_vol, counts = measure.label(result_vol>0.8, connectivity=3, return_num=True)    \n",
    "result_props = measure.regionprops(label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, label_vol.shape[2]): \n",
    "    imageio.imwrite('detections/detection' + str(n).zfill(2) + '.tiff', label_vol[:, :, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "arealist = [] \n",
    "slicelist = [] \n",
    "\n",
    "for n in range(0, len(result_props)): \n",
    "    slicelist.append(result_props[n].bbox[5]-result_props[n].bbox[2])\n",
    "    arealist.append(result_props[n].area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_list = list(range(1, len(result_props)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Detection_label','Detection_slices', 'Detection_pixels'])\n",
    "df['Detection_label'] = detection_list\n",
    "\n",
    "df['Detection_slices'] = slicelist\n",
    "df['Detection_pixels'] = arealist\n",
    "# df.to_csv('detection_information_oct25_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['F002-GABA-4th.tif',\\\n",
    "'F002-Geph-4th.tif',\\\n",
    "'F002-GluA1-1st.tif',\\\n",
    "'F002-GluA2-2nd.tif',\\\n",
    "'F002-GluA3-2nd.tif',\\\n",
    "'F002-GluA4-3rd.tif',\\\n",
    "'F002-GluN1-1st.tif',\\\n",
    "'F002-GluN2-3rd.tif',\\\n",
    "'F002-MBP64-3rd.tif',\\\n",
    "'F002-PSD95-4th.tif',\\\n",
    "'F002-Syn12-2nd.tif',\\\n",
    "'F002-VGluT1-1st.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-release",
   "metadata": {},
   "source": [
    "## Match PSD signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload PSD \n",
    "psd_vol = skio.imread('data/F002-PSD95-4th.tif', plugin='tifffile')\n",
    "psd_data = np.transpose(psd_vol, (1, 2, 0))\n",
    "psd_data = np.double(psd_data)\n",
    "\n",
    "# select only slices 5-48\n",
    "psd_data = psd_data[:, :, 4:]\n",
    "\n",
    "# Create a dictionary object to hold the image data \n",
    "synaptic_volumes = {'presynaptic': [], 'postsynaptic': [psd_data]}\n",
    "\n",
    "# Specify the minimum number of slices each blob should span \n",
    "min_num_of_slices = 1\n",
    "\n",
    "# Create query dictionary object \n",
    "query = {'preIF': [], 'preIF_z': [1],\n",
    "         'postIF': ['psd_data'], 'postIF_z': [1],\n",
    "         'punctumSize': 2}\n",
    "\n",
    "psd_probability_map = syn.getSynapseDetections(synaptic_volumes, query)\n",
    "    \n",
    "# np.savez('PSD1_SYN1.npz', result_vol)\n",
    "psd_label_vol, counts = measure.label(psd_probability_map>0.8, connectivity=3, return_num=True)\n",
    "psd_props = measure.regionprops(psd_label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, label_vol.shape[2]): \n",
    "    imageio.imwrite('psd_label/detection' + str(n).zfill(2) + '.tiff', psd_label_vol[:, :, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-perth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for annoitr in range(0, len(result_props)): \n",
    "    foo = result_props[annoitr]\n",
    "    psdlabellist = []\n",
    "    for n in range(0, len(foo.coords)): \n",
    "        psdlabellist.append(psd_label_vol[foo.coords[n][0], foo.coords[n][1], foo.coords[n][2]]) \n",
    "    \n",
    "    \n",
    "    if len(np.unique(psdlabellist)) > 1: \n",
    "        print(annoitr, len(np.unique(psdlabellist))) \n",
    "    if np.unique(psdlabellist)[0] == 0: \n",
    "        print(\"zero\", annoitr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-tokyo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_vol = skio.imread('normalized_data/F002-PSD95-4thP.tif', plugin='tifffile')\n",
    "psd_data = np.transpose(psd_vol, (1, 2, 0))\n",
    "\n",
    "psd_data = np.double(psd_data)\n",
    "\n",
    "# select only slices 5-48\n",
    "psd_data = psd_data[:, :, 4:]\n",
    "\n",
    "PSD_label_list = [] \n",
    "intensity_sum_list = [] \n",
    "intensity_avg_list = []\n",
    "number_of_slices_list = [] \n",
    "number_of_pixels_list = [] \n",
    "\n",
    "\n",
    "for n_detection in tqdm(range(0, len(result_props))): \n",
    "    \n",
    "    detection_object = result_props[n_detection]\n",
    "    psdlabel_number = psd_label_vol[detection_object.coords[0][0],\\\n",
    "                                    detection_object.coords[0][1],\\\n",
    "                                    detection_object.coords[0][2]]\n",
    "     \n",
    "    psd_object = psd_props[psdlabel_number-1]\n",
    "    PSD_label_list.append(psdlabel_number)              \n",
    "    output_list = [] \n",
    "    \n",
    "    mask = psd_label_vol==psdlabel_number\n",
    "    masked_vol = psd_data*mask\n",
    "    summed_intensity = np.sum(masked_vol)\n",
    "    avg_intensity = summed_intensity/len(psd_object.coords)\n",
    "\n",
    "    \n",
    "    if len(psd_object.coords) > 500: \n",
    "        intensity_sum_list.append(np.nan)\n",
    "        intensity_avg_list.append(np.nan)\n",
    "        number_of_slices_list.append(np.nan)\n",
    "        number_of_pixels_list.append(np.nan)\n",
    "    else: \n",
    "        intensity_sum_list.append(summed_intensity)\n",
    "        intensity_avg_list.append(avg_intensity)\n",
    "        number_of_slices_list.append(psd_object.bbox[5] - psd_object.bbox[2] + 1)\n",
    "        number_of_pixels_list.append(len(psd_object.coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PSD_label'] = PSD_label_list\n",
    "\n",
    "df['PSD_intensity_sum'] = intensity_sum_list\n",
    "df['PSD_intensity_avg'] = intensity_avg_list\n",
    "df['PSD_slices'] = number_of_slices_list\n",
    "df['PSD_pixels'] = number_of_pixels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(number_of_slices_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pd.isnull(df['PSD_intensity_avg'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-portugal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "drawn-seeking",
   "metadata": {},
   "source": [
    "## SYNAPSIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload Synapsin \n",
    "syn_vol = skio.imread('data/F002-Syn12-2nd.tif', plugin='tifffile')\n",
    "syn_vol = np.transpose(syn_vol, (1, 2, 0))\n",
    "syn_vol = np.double(syn_vol)\n",
    "\n",
    "# select only slices 5-48\n",
    "syn_vol = syn_vol[:, :, 4:]\n",
    "\n",
    "# Create a dictionary object to hold the image data \n",
    "synaptic_volumes = {'presynaptic': [], 'postsynaptic': [syn_vol]}\n",
    "\n",
    "# Specify the minimum number of slices each blob should span \n",
    "min_num_of_slices = 1\n",
    "\n",
    "# Create query dictionary object \n",
    "query = {'preIF': [], 'preIF_z': [1],\n",
    "         'postIF': ['syn_vol'], 'postIF_z': [1],\n",
    "         'punctumSize': 2}\n",
    "\n",
    "syn_probability_map = syn.getSynapseDetections(synaptic_volumes, query)\n",
    "    \n",
    "# np.savez('PSD1_SYN1.npz', result_vol)\n",
    "syn_label_vol, counts = measure.label(syn_probability_map>0.8, connectivity=3, return_num=True)\n",
    "syn_props = measure.regionprops(syn_label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(syn_vol[60:110, 375:440, 15])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(syn_probability_map[60:110, 375:440, 15])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, label_vol.shape[2]): \n",
    "    imageio.imwrite('syn_label/detection' + str(n).zfill(2) + '.tiff', syn_label_vol[:, :, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_synapsin_list = [] \n",
    "\n",
    "for annoitr in range(0, len(result_props)): \n",
    "    biggest_label = 0 \n",
    "    result_object = result_props[annoitr]\n",
    "    synlabellist = []\n",
    "\n",
    "    if result_object.bbox[1]<=3: \n",
    "        mincol = 0\n",
    "    else: \n",
    "        mincol = result_object.bbox[1] - 3\n",
    "    if result_object.bbox[4]>=syn_label_vol.shape[1]-3: \n",
    "        maxcol = result_object.bbox[4]\n",
    "    else: \n",
    "        maxcol = result_object.bbox[4] + 3\n",
    "\n",
    "    if result_object.bbox[0]<=3: \n",
    "        minrow = 0\n",
    "    else: \n",
    "        minrow = result_object.bbox[0] - 3\n",
    "    if result_object.bbox[3]>=syn_label_vol.shape[0]-3: \n",
    "        maxrow = result_object.bbox[3]\n",
    "    else: \n",
    "        maxrow = result_object.bbox[3] + 3\n",
    "\n",
    "    if result_object.bbox[2]==0: \n",
    "        minslice = 0\n",
    "    else: \n",
    "        minslice = result_object.bbox[2] - 1\n",
    "    if result_object.bbox[5]==syn_label_vol.shape[2]-1: \n",
    "        maxslice = result_object.bbox[5]\n",
    "    else: \n",
    "        maxslice = result_object.bbox[5] + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    output = syn_label_vol[minrow:maxrow,\\\n",
    "                           mincol:maxcol,\\\n",
    "                           minslice:maxslice]\n",
    "    unique_vals, unique_counts = np.unique(output, return_counts=True)\n",
    "    if unique_vals[0]==0 and len(unique_vals)>0: \n",
    "\n",
    "        if len(unique_vals) > 2: \n",
    "            biggest_label_ind = np.argmax(unique_counts[1:])\n",
    "            biggest_label = unique_vals[biggest_label_ind+1]\n",
    "            \n",
    "        elif len(unique_vals) == 2: \n",
    "            biggest_label = unique_vals[1]\n",
    "        \n",
    "    else: \n",
    "        biggest_label = unique_vals[0]\n",
    "        print(unique_vals[0])\n",
    "       \n",
    "    matched_synapsin_list.append(biggest_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_synapsin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.array(matched_synapsin_list) == 0) [0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-assault",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload Synapsin \n",
    "syn_vol = skio.imread('normalized_data/F002-Syn12-2ndP.tif', plugin='tifffile')\n",
    "syn_vol = np.transpose(syn_vol, (1, 2, 0))\n",
    "syn_vol = np.double(syn_vol)\n",
    "\n",
    "# select only slices 5-48\n",
    "syn_vol = syn_vol[:, :, 4:]\n",
    "\n",
    "intensity_sum_list = [] \n",
    "intensity_avg_list = []\n",
    "number_of_slices_list = [] \n",
    "number_of_pixels_list = [] \n",
    "\n",
    "for syn_label in tqdm(matched_synapsin_list): \n",
    "    \n",
    "    if syn_label == 0: \n",
    "        intensity_sum_list.append(0)\n",
    "        intensity_avg_list.append(0)\n",
    "        number_of_slices_list.append(0)\n",
    "        number_of_pixels_list.append(0)\n",
    "    \n",
    "    else: \n",
    "        syn_object = syn_props[syn_label-1]\n",
    "\n",
    "        output_list = [] \n",
    "\n",
    "        mask = syn_label_vol==syn_label\n",
    "        masked_vol = syn_vol*mask\n",
    "        summed_intensity = np.sum(masked_vol)\n",
    "        avg_intensity = summed_intensity/len(syn_object.coords)\n",
    "\n",
    "        \n",
    "        if len(syn_object.coords) > 4500: \n",
    "            intensity_sum_list.append(np.nan)\n",
    "            intensity_avg_list.append(np.nan)\n",
    "            number_of_slices_list.append(np.nan)\n",
    "            number_of_pixels_list.append(np.nan)\n",
    "        else: \n",
    "            intensity_sum_list.append(summed_intensity)\n",
    "            intensity_avg_list.append(avg_intensity)\n",
    "            number_of_slices_list.append(syn_object.bbox[5] - syn_object.bbox[2] + 1)\n",
    "            number_of_pixels_list.append(len(syn_object.coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-disease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['SYN_label'] = matched_synapsin_list\n",
    "df['SYN_intensity_sum'] = intensity_sum_list\n",
    "df['SYN_intensity_avg'] = intensity_avg_list\n",
    "df['SYN_slices'] = number_of_slices_list\n",
    "df['SYN_pixels'] = number_of_pixels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-example",
   "metadata": {},
   "source": [
    "## Find postsynaptic overlap with PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(fn): \n",
    "    syn_vol = skio.imread(fn, plugin='tifffile')\n",
    "    syn_vol = np.transpose(syn_vol, (1, 2, 0))\n",
    "    syn_vol = np.double(syn_vol)\n",
    "\n",
    "    # select only slices 5-48\n",
    "    syn_vol = syn_vol[:, :, 4:]\n",
    "    \n",
    "    return syn_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSingleSliceDetections(fn): \n",
    "    # fn - 'data/F002-Syn12-2nd.tif'\n",
    "    syn_vol = skio.imread(fn, plugin='tifffile')\n",
    "    syn_vol = np.transpose(syn_vol, (1, 2, 0))\n",
    "    syn_vol = np.double(syn_vol)\n",
    "\n",
    "    # select only slices 5-48\n",
    "    syn_vol = syn_vol[:, :, 4:]\n",
    "\n",
    "    # Create a dictionary object to hold the image data \n",
    "    synaptic_volumes = {'presynaptic': [], 'postsynaptic': [syn_vol]}\n",
    "\n",
    "    # Specify the minimum number of slices each blob should span \n",
    "    min_num_of_slices = 1\n",
    "\n",
    "    # Create query dictionary object \n",
    "    query = {'preIF': [], 'preIF_z': [1],\n",
    "             'postIF': ['syn_vol'], 'postIF_z': [1],\n",
    "             'punctumSize': 2}\n",
    "\n",
    "    syn_probability_map = syn.getSynapseDetections(synaptic_volumes, query)\n",
    "\n",
    "    # np.savez('PSD1_SYN1.npz', result_vol)\n",
    "    syn_label_vol, counts = measure.label(syn_probability_map>0.8, connectivity=3, return_num=True)\n",
    "    syn_props = measure.regionprops(syn_label_vol)\n",
    "    \n",
    "    return syn_label_vol, syn_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptor_filelist = \\\n",
    "['data/F002-GluA1-1st.tif',\\\n",
    "'data/F002-GluA2-2nd.tif',\\\n",
    "'data/F002-GluA3-2nd.tif',\\\n",
    "'data/F002-GluA4-3rd.tif',\\\n",
    "'data/F002-GluN1-1st.tif',\\\n",
    "'data/F002-GluN2-3rd.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_receptor_filelist = \\\n",
    "['normalized_data/F002-GluA1-1stP.tif',\\\n",
    "'normalized_data/F002-GluA2-2ndP.tif',\\\n",
    "'normalized_data/F002-GluA3-2ndP.tif',\\\n",
    "'normalized_data/F002-GluA4-3rdP.tif',\\\n",
    "'normalized_data/F002-GluN1-1stP.tif',\\\n",
    "'normalized_data/F002-GluN2-3rdP.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each PSD blob, find blob somewhere else\n",
    "receptor_matched_list = []\n",
    "\n",
    "for n_fn, fn in enumerate(receptor_filelist): \n",
    "    print(fn)\n",
    "    intensity_sum_list = [] \n",
    "    intensity_avg_list = []\n",
    "    number_of_slices_list = [] \n",
    "    number_of_pixels_list = [] \n",
    "\n",
    "    matched_receptor_list = [] \n",
    "\n",
    "    for n in tqdm(range(0, len(PSD_label_list))): \n",
    "        psdlabel_number = PSD_label_list[n]\n",
    "        psd_object = psd_props[psdlabel_number-1]\n",
    "        psd_mask = psd_label_vol==psdlabel_number\n",
    "        \n",
    "        data = loaddata(normalized_receptor_filelist[n_fn])\n",
    "        \n",
    "        output = data*psd_mask\n",
    "            \n",
    "        summed_intensity = np.sum(output)\n",
    "\n",
    "        if summed_intensity==0: \n",
    "            intensity_sum_list.append(0)\n",
    "            intensity_avg_list.append(0)\n",
    "            number_of_slices_list.append(0)\n",
    "            number_of_pixels_list.append(0)\n",
    "        else: \n",
    "            data_label_vol, counts = measure.label(output>0, connectivity=3, return_num=True)\n",
    "            data_props = measure.regionprops(data_label_vol)\n",
    "            data_object = data_props[0]\n",
    "            \n",
    "            avg_intensity = summed_intensity/len(data_object.coords)\n",
    "\n",
    "            intensity_sum_list.append(summed_intensity)\n",
    "            intensity_avg_list.append(avg_intensity)\n",
    "            number_of_slices_list.append(data_object.bbox[5] - data_object.bbox[2] + 1)\n",
    "            number_of_pixels_list.append(len(data_object.coords))\n",
    "\n",
    "                \n",
    "    channel_name = fn.split('-')[1]\n",
    "    ch_label = channel_name + '_label'\n",
    "    intensity_sum = channel_name + '_intensity_sum'\n",
    "    intensity_avg = channel_name + '_intensity_avg'\n",
    "    ch_slices = channel_name + '_slices'\n",
    "    ch_pixels = channel_name + '_pixels'\n",
    "    \n",
    "    df[intensity_sum] = intensity_sum_list\n",
    "    df[intensity_avg] = intensity_avg_list\n",
    "    df[ch_slices] = number_of_slices_list\n",
    "    df[ch_pixels] = number_of_pixels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "transmitter_filelist = ['normalized_data/F002-VGluT1-1stP.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_synapsin_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each synapsin blob, find blob somewhere else\n",
    "\n",
    "for n_fn, fn in enumerate(transmitter_filelist): \n",
    "    print(fn)\n",
    "    intensity_sum_list = [] \n",
    "    intensity_avg_list = []\n",
    "    number_of_slices_list = [] \n",
    "    number_of_pixels_list = [] \n",
    "\n",
    "    for n in tqdm(range(0, len(matched_synapsin_list))): \n",
    "        synlabel_number = matched_synapsin_list[n]\n",
    "        syn_object = syn_props[synlabel_number-1]\n",
    "        syn_mask = syn_label_vol==synlabel_number\n",
    "        \n",
    "        data = loaddata(transmitter_filelist[n_fn])\n",
    "        \n",
    "        output = data*syn_mask\n",
    "        \n",
    "        summed_intensity = np.sum(output)\n",
    "\n",
    "        if summed_intensity==0: \n",
    "            intensity_sum_list.append(0)\n",
    "            intensity_avg_list.append(0)\n",
    "            number_of_slices_list.append(0)\n",
    "            number_of_pixels_list.append(0)\n",
    "        else: \n",
    "            data_label_vol, counts = measure.label(output>0, connectivity=3, return_num=True)\n",
    "            data_props = measure.regionprops(data_label_vol)\n",
    "            data_object = data_props[0]\n",
    "            \n",
    "            avg_intensity = summed_intensity/len(data_object.coords)\n",
    "\n",
    "            intensity_sum_list.append(summed_intensity)\n",
    "            intensity_avg_list.append(avg_intensity)\n",
    "            number_of_slices_list.append(data_object.bbox[5] - data_object.bbox[2] + 1)\n",
    "            number_of_pixels_list.append(len(data_object.coords))\n",
    "\n",
    "                \n",
    "    channel_name = fn.split('-')[1]\n",
    "    ch_label = channel_name + '_label'\n",
    "    intensity_sum = channel_name + '_intensity_sum'\n",
    "    intensity_avg = channel_name + '_intensity_avg'\n",
    "    ch_slices = channel_name + '_slices'\n",
    "    ch_pixels = channel_name + '_pixels'\n",
    "    \n",
    "    df[intensity_sum] = intensity_sum_list\n",
    "    df[intensity_avg] = intensity_avg_list\n",
    "    df[ch_slices] = number_of_slices_list\n",
    "    df[ch_pixels] = number_of_pixels_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_nov8_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-command",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
